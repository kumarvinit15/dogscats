{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape | 25000\n",
      "test_images.shape   | 12500\n",
      "train_dogs.shape | 12500\n",
      "train_cats.shape   | 12500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random, cv2\n",
    "\n",
    "\n",
    "TRAIN_DIR = 'C:/Users/nikki/Desktop/Capstone Final/data/dogscats/train/'\n",
    "TEST_DIR = 'C:/Users/nikki/Desktop/Capstone Final/data/dogscats/test/'\n",
    "\n",
    "# load the full dataset\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] \n",
    "train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "# load the full test set\n",
    "test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "test_save = test_images\n",
    "# print the number of images loaded for both training and testing\n",
    "print('train_images.shape | {0}'.format(len(train_images)))\n",
    "print('test_images.shape   | {0}'.format(len(test_images)))\n",
    "print('train_dogs.shape | {0}'.format(len(train_dogs)))\n",
    "print('train_cats.shape   | {0}'.format(len(train_cats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: 10400\n",
      "valid shape: 2600\n",
      "Test shape: 5000\n"
     ]
    }
   ],
   "source": [
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "CHANNELS = 3\n",
    "train_target = []\n",
    "test_images = test_images[:5000]\n",
    "# slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\n",
    "train_images = train_dogs[:6500] + train_cats[:6500]\n",
    "train_targets = np.append(np.ones(6500), np.zeros(6500))\n",
    "\n",
    "#random.shuffle(train_images)\n",
    "#train_images, train_targets = shuffle(train_images, train_targets, random_state=0)\n",
    "\n",
    "# split the dataset into training and testing\n",
    "train_images, valid_images, train_targets, valid_targets = train_test_split(train_images, train_targets, test_size=0.20, random_state=10)\n",
    "\n",
    "\n",
    "print(\"Train shape: {}\".format(len(train_images)))\n",
    "print(\"valid shape: {}\".format(len(valid_images)))\n",
    "print(\"Test shape: {}\".format(len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 0., 1., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikki\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10400/10400 [05:05<00:00, 34.00it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2600/2600 [01:53<00:00, 22.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [02:39<00:00, 31.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_images = paths_to_tensor(train_images)#.astype('float32')/255\n",
    "valid_images = paths_to_tensor(valid_images)#.astype('float32')/255\n",
    "test_images = paths_to_tensor(test_images)#.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benchmark Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.utils import plot_model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "# First Convolutional Layer\n",
    "model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile the benchmark architecture\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Benchmark\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.benchmark_from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history_cnn = model.fit(train_images[:10000], train_targets[:10000], \n",
    "          validation_data=(valid_images[:2500], valid_targets[:2500]),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(IMPLEMENTATION) Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "# First Convolutional Layer\n",
    "model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(32, kernel_size=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "# Global average pooling layer\n",
    "#model.add(GlobalAveragePooling2D())  \n",
    "# Fully connected layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "#plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(IMPLEMENTATION) Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_new_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history_cnn = model.fit(train_images[:10000], train_targets[:10000], \n",
    "          validation_data=(valid_images[:2500], valid_targets[:2500]),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the Model with the Best Validation Loss and plot Loss and Accuracy curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "%matplotlib inline \n",
    "model.load_weights('saved_models/weights.best.from_new_scratch.hdf5')\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history_cnn.history['acc'])\n",
    "plt.plot(history_cnn.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history_cnn.history['loss'])\n",
    "plt.plot(history_cnn.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = paths_to_tensor(test_images[:25]).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_new_scratch.hdf5')\n",
    "# get the prediction in test set\n",
    "predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Format for Kaggle submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show an images\n",
    "def show_image(img_path):\n",
    "    img = cv2.imread(img_path) \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def cat_dog_prediction(test_images, predictions):\n",
    "    # test human face is detected\n",
    "    for i in range(len(predictions)): \n",
    "        if predictions[i] == 1:\n",
    "            print(\"This image contains dog\")\n",
    "            show_image(test_images[i]) # display the image\n",
    "        else:\n",
    "            print(\"This image contains cat\")\n",
    "            show_image(test_images[i]) # display the image\n",
    "        print(\"------------------------------------------------\")\n",
    "\n",
    "cat_dog_prediction(test_save[:25], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "with open(\"submission_model_1.csv\",\"w\") as f:\n",
    "    f.write(\"id,label\\n\")\n",
    "    for i in range(len(predictions)):\n",
    "        f.write(str(i+1)+\",\"+str(predictions[i])+\"\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
